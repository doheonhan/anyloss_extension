{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79042d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1e-5\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "################################ MSE ################################\n",
    "def MSE(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.math.square(y_true-y_pred))\n",
    "\n",
    "################################ BCE ################################\n",
    "def BCE(y_true, y_pred):\n",
    "    return -tf.reduce_mean(y_true*tf.math.log(y_pred+s)+(1-y_true)*tf.math.log(1-y_pred+s))\n",
    "\n",
    "################################ WBCE ################################\n",
    "def WBCE(y_true, y_pred):\n",
    "    N = batch    # batch_size\n",
    "    y1 = tf.reduce_sum(y_true)\n",
    "    y0 = N-y1\n",
    "    w1 = y0/N #N/y1\n",
    "    w0 = y1/N #N/y0\n",
    "    return -tf.reduce_mean(w1*y_true*tf.math.log(y_pred+s)+w0*(1-y_true)*tf.math.log(1-y_pred+s))\n",
    "\n",
    "################################ TN/FP/FN/TP ################################\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    N = batch    # batch_size\n",
    "    y1 = tf.reduce_sum(y_true)\n",
    "    y0 = N-y1\n",
    "    TN = N-tf.reduce_sum(y_true)-tf.reduce_sum(y_pred)+tf.reduce_sum(y_true*y_pred)\n",
    "    FP = tf.reduce_sum(y_pred)-tf.reduce_sum(y_true*y_pred)\n",
    "    FN = tf.reduce_sum(y_true)-tf.reduce_sum(y_true*y_pred)\n",
    "    TP = tf.reduce_sum(y_true*y_pred)\n",
    "    return N, y1, y0, TN, FP, FN, TP\n",
    "\n",
    "################################ make_lists ################################\n",
    "def make_lists():\n",
    "    list_acc = []\n",
    "    list_f1 = []\n",
    "    list_gmean = []\n",
    "    list_bacc = []\n",
    "    list_pre = []\n",
    "    list_rec = []\n",
    "    list_spe = []\n",
    "    return list_acc, list_f1, list_gmean, list_bacc, list_pre, list_rec, list_spe\n",
    "    \n",
    "############################### Results ###############################\n",
    "def get_results(y_true, y_pred):\n",
    "    TN = metrics.confusion_matrix(y_true, y_pred)[0,0]\n",
    "    FP = metrics.confusion_matrix(y_true, y_pred)[0,1]\n",
    "    FN = metrics.confusion_matrix(y_true, y_pred)[1,0]\n",
    "    TP = metrics.confusion_matrix(y_true, y_pred)[1,1]\n",
    "    acc = np.round((TP+TN)/(TP+TN+FP+FN),4)\n",
    "    if TP+FP == 0:\n",
    "        pre = 0\n",
    "    else:\n",
    "        pre = np.round(TP/(TP+FP),4)\n",
    "    rec = np.round(TP/(TP+FN),4)\n",
    "    spe = np.round(TN/(TN+FP),4)\n",
    "    f1 = np.round(TP/(TP + 0.5*(FP+FN)),4)\n",
    "    f05 = np.round(TP/(TP + 0.8*FP + 0.2*FN),4)\n",
    "    f2 = np.round(TP/(TP + 0.2*FP + 0.8*FN),4)\n",
    "    gmean = np.round(((TP/(TP+FN)) * (TN/(TN+FP)))**0.5,4)\n",
    "    bacc = np.round(0.5*(TP/(TP+FN) + TN/(TN+FP)),4)\n",
    "    \n",
    "    list_acc.append(acc)\n",
    "    list_f1.append(f1)\n",
    "    list_gmean.append(gmean)\n",
    "    list_bacc.append(bacc)\n",
    "    list_pre.append(pre)\n",
    "    list_rec.append(rec)\n",
    "    list_spe.append(spe)\n",
    "\n",
    "################################ SPL ################################\n",
    "def splitter(y_pred):\n",
    "    return (0.5)**2-(y_pred-0.5)**2\n",
    "\n",
    "# =================================== Fbeta =================================== #\n",
    "################################ Pure_Fbeta ################################\n",
    "def Pure_Fbeta(y_true, y_pred):\n",
    "    b = 1 \n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    F_beta = ((1+b**2)*TP) / ((b**2)*y1 + tf.reduce_sum(y_pred)+s)  # (1+b**2)TP/((1+b**2)TP+FP+b**2FN)\n",
    "    return 1-F_beta\n",
    "\n",
    "################################ Any_Fbeta ################################\n",
    "def Any_Fbeta(y_true, y_pred):\n",
    "    b = 1 \n",
    "    y_pred = 1/(1+tf.math.exp(-L*(y_pred-0.5)))\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    F_beta = ((1+b**2)*TP) / ((b**2)*y1 + tf.reduce_sum(y_pred)+s)  # (1+b**2)TP/((1+b**2)TP+FP+b**2FN)\n",
    "    return 1-F_beta\n",
    "\n",
    "################################ WBCEFL ################################\n",
    "def WBCEFL(y_true, y_pred):\n",
    "    b = 1\n",
    "    WBCEloss = WBCE(y_true, y_pred)\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    F_beta = ((1+b**2)*TP) / ((b**2)*y1 + tf.reduce_sum(y_pred)+s)  # (1+b**2)TP/((1+b**2)TP+FP+b**2FN)\n",
    "    return (1-r)*WBCEloss+(r)*(1-F_beta)\n",
    "\n",
    "################################ SPLFL ################################\n",
    "def SPLFL(y_true, y_pred):\n",
    "    b = 1\n",
    "    SPL = splitter(y_pred)\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    F_beta = ((1+b**2)*TP) / ((b**2)*y1 + tf.reduce_sum(y_pred)+s)  # (1+b**2)TP/((1+b**2)TP+FP+b**2FN)\n",
    "    return (1-w)*SPL+(w)*(1-F_beta)\n",
    "\n",
    "# =================================== Gmean =================================== #\n",
    "################################ Pure_Gmean ################################\n",
    "def Pure_Gmean(y_true, y_pred):\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    sur_gmean = (TP*TN)/(y1*y0+s)\n",
    "    return 1-sur_gmean\n",
    "\n",
    "################################ Any_Gmean ################################\n",
    "def Any_Gmean(y_true, y_pred):\n",
    "    y_pred = 1/(1+tf.math.exp(-L*(y_pred-0.5)))\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    sur_gmean = (TP*TN)/(y1*y0+s)\n",
    "    return 1-sur_gmean\n",
    "\n",
    "################################ WBCEGL ################################\n",
    "def WBCEGL(y_true, y_pred):\n",
    "    WBCEloss = WBCE(y_true, y_pred)\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    sur_gmean = (TP*TN)/(y1*y0+s)\n",
    "    return (1-r)*WBCEloss+(r)*(1-sur_gmean)\n",
    "\n",
    "################################ SPLGL ################################\n",
    "def SPLGL(y_true, y_pred):\n",
    "    SPL = splitter(y_pred)\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    sur_gmean = (TP*TN)/(y1*y0+s)\n",
    "    return (1-w)*SPL+(w)*(1-sur_gmean)\n",
    "\n",
    "# =================================== BAccu =================================== #\n",
    "################################ Pure_BAccu ################################\n",
    "def Pure_BAccu(y_true, y_pred):\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    baccu = (y0*TP+y1*TN) / (2*y1*y0+s)\n",
    "    return 1-baccu\n",
    "\n",
    "################################ Any_BAccu ################################\n",
    "def Any_BAccu(y_true, y_pred):\n",
    "    y_pred = 1/(1+tf.math.exp(-L*(y_pred-0.5)))\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    baccu = (y0*TP+y1*TN) / (2*y1*y0+s)\n",
    "    return 1-baccu\n",
    "\n",
    "################################ WBCEBL ################################\n",
    "def WBCEBL(y_true, y_pred):\n",
    "    WBCEloss = WBCE(y_true, y_pred)\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    baccu = (y0*TP+y1*TN) / (2*y1*y0+s)\n",
    "    return (1-r)*WBCEloss+(r)*(1-baccu)\n",
    "\n",
    "################################ SPLBL ################################\n",
    "def SPLBL(y_true, y_pred):\n",
    "    SPL = splitter(y_pred)\n",
    "    N, y1, y0, TN, FP, FN, TP = confusion_matrix(y_true, y_pred)\n",
    "    baccu = (y0*TP+y1*TN) / (2*y1*y0+s)\n",
    "    return (1-w)*SPL+(w)*(1-baccu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'MSE':[0, 0, 0, 0, 0, 0, 0]}, index = ['Acc','F1','G_Mean','B_Acc','Pre','Rec','Spe'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd16127",
   "metadata": {},
   "source": [
    "# Step1: Select One Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f309387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8f9bd17",
   "metadata": {},
   "source": [
    "## 1)SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311384ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bd910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://www.kaggle.com/uciml/sms-spam-collection-dataset\n",
    "data = pd.read_csv('spam.csv', encoding='latin1')\n",
    "print('sample number:',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Unnamed: 2']\n",
    "del data['Unnamed: 3']\n",
    "del data['Unnamed: 4']\n",
    "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b739215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing?\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1adc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique?\n",
    "data['v2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicate\n",
    "data.drop_duplicates(subset=['v2'], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d52531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicate\n",
    "data.drop_duplicates(subset=['v2'], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805309be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[:700][data['v1'][:700] == 1].index, inplace=True)\n",
    "numlist = list(range(len(data)))\n",
    "data = data.set_index(pd.Index(numlist))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b296bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['v2']\n",
    "y = data['v1']\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d75ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encoding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_encoded = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b828b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index (more frequent, smaller number given)\n",
    "word_to_index = tokenizer.word_index\n",
    "# print(len(word_to_index), word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b75a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word group for padding\n",
    "vocab_size = len(word_to_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word group for padding\n",
    "vocab_size = len(word_to_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dab600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "max_len = maxlen\n",
    "X_padded = pad_sequences(X_encoded, maxlen = max_len)\n",
    "X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844552f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "epochs = 20\n",
    "batch = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2fe88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c0c3dd3",
   "metadata": {},
   "source": [
    "## 2)Reuters News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02871f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "maxlen = 100\n",
    "(XX, yy), (X_dummy, y_dummy) = reuters.load_data(num_words=vocab_size, test_split=0)\n",
    "\n",
    "print(len(XX))\n",
    "print(len(X_dummy))\n",
    "num_classes = len(set(yy))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = reuters.get_word_index()\n",
    "# print(len(word_to_index), word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afcc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "max_len = maxlen\n",
    "X_padded = pad_sequences(XX, maxlen = max_len)\n",
    "X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f30fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking only label 3->'0' & 1->'1'\n",
    "idx_1 = []\n",
    "idx_3 = []\n",
    "for i in range(len(yy)):\n",
    "    if list(yy)[i] == 1:\n",
    "        idx_1.append(i)\n",
    "    if list(yy)[i] == 3:\n",
    "        idx_3.append(i)\n",
    "print(len(idx_1), len(idx_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = idx_1[:100] + idx_3[:800]\n",
    "idx.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3755c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in idx:\n",
    "    X.append(X_padded[i])\n",
    "    y.append(yy[i])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = (y == 1)\n",
    "y3 = list(y3)\n",
    "\n",
    "y_3 = []\n",
    "for i in range(len(y3)):\n",
    "    if y3[i] == True:\n",
    "        y_3.append(1)\n",
    "    else:\n",
    "        y_3.append(0)\n",
    "y_3 = np.array(y_3)\n",
    "\n",
    "print(pd.Series(y_3).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = X\n",
    "y_3 = y_3.astype(float)\n",
    "print(X_padded.shape, y_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "epochs = 20\n",
    "batch = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bb2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f12894",
   "metadata": {},
   "source": [
    "## 3)IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a13bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceefd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_len = 100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0883422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making lists of index\n",
    "idx_0 = []\n",
    "idx_1 = []\n",
    "for i in range(len(y_train)):\n",
    "    if list(y_train)[i] == 0:\n",
    "        idx_0.append(i)\n",
    "    if list(y_train)[i] == 1:\n",
    "        idx_1.append(i)\n",
    "print(len(idx_0), len(idx_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e415f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = idx_0[:450] + idx_1[:150]\n",
    "idx.sort()\n",
    "# print(len(idx), idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f694ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in idx:\n",
    "    X.append(X_train[i])\n",
    "    y.append(y_train[i])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "# print(len(word_to_index), word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1bf6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "X_padded = pad_sequences(X, maxlen = max_len)\n",
    "X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "epochs = 20\n",
    "batch = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d866d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e170fc3",
   "metadata": {},
   "source": [
    "# Step2: Select One Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbbd50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d84d38fa",
   "metadata": {},
   "source": [
    "## 1)RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bde2d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "embedding_dim = 32\n",
    "hidden_units = 32\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim))\n",
    "    # model.add(SimpleRNN(hidden_units))\n",
    "    model.add(LSTM(hidden_units))\n",
    "    # model.add(GRU(hidden_units))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9399500f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_acc = []\n",
    "mse_f1 = []\n",
    "mse_gmean = []\n",
    "mse_bacc = []\n",
    "mse_pre = []\n",
    "mse_rec = []\n",
    "mse_spe = []\n",
    "\n",
    "for i in range(5):\n",
    "    print('#'*50,'{0}th repeat'.format(i+1),'#'*50)\n",
    "    list_acc, list_f1, list_gmean, list_bacc, list_pre, list_rec, list_spe = make_lists()\n",
    "\n",
    "    n_iter=0\n",
    "    ###################### MLP (sigmoid // MSE) ##############################\n",
    "    for train_index, test_index in skf.split(X_padded, y):\n",
    "        n_iter += 1\n",
    "        X_train = X_padded[train_index]\n",
    "        y_train= y[train_index]\n",
    "        X_test = X_padded[test_index]\n",
    "        y_test= y[test_index]\n",
    "#         print('#'*50,'{0}th CV'.format(n_iter),'#'*50)\n",
    "    #     X_train = np.array(X_train)\n",
    "    #     y_train = np.array(y_train)\n",
    "    #     y_train = y_train.astype(float)\n",
    "    #     X_test = np.array(X_test)\n",
    "    #     y_test = np.array(y_test)\n",
    "    #     y_test = y_test.astype(float)\n",
    "\n",
    "        model = create_model()\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=0, min_delta=1e-4)\n",
    "    #     check_point = ModelCheckpoint('best_model.h5', monitor=\"val_loss\", save_best_only=True, save_weights_only=True)\n",
    "        opt = optimizers.Adam(learning_rate = 0.001)\n",
    "        model.compile(optimizer=opt, loss=MSE, metrics=['accuracy'])\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=0, epochs=epochs, batch_size = batch, ) \n",
    "                            #callbacks=[early_stopping]) #, check_point])\n",
    "#         plt.plot(history.history['loss'], label='loss')\n",
    "#         plt.ylim([0, 1])\n",
    "#         plt.xlabel('Iteration',fontweight=\"bold\",fontsize = 15)\n",
    "#         plt.ylabel('Loss',fontweight=\"bold\",fontsize = 15)\n",
    "#         plt.title(\"Cost Function\",fontweight=\"bold\",fontsize = 20)\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        predicted = []\n",
    "    #     model.load_weights('best_model.h5')  # Best Model by Check_Point\n",
    "        result = model.predict(X_test)\n",
    "        for i in range(X_test.shape[0]):\n",
    "            if result[i] <= 0.5:\n",
    "                predicted.append(0)\n",
    "            else:\n",
    "                predicted.append(1)\n",
    "        get_results(y_test, predicted)\n",
    "    print(\"Acc:{}\\nF1:{}\\nGM:{}\\nBA:{}\\nPRE:{}\\nREC:{}\\nSPE:{}\\n\".format(np.mean(list_acc),np.mean(list_f1),np.mean(list_gmean),\n",
    "                                                                         np.mean(list_bacc),np.mean(list_pre),np.mean(list_rec),\n",
    "                                                                         np.mean(list_spe)))     \n",
    "    mse_acc.append(np.mean(list_acc))\n",
    "    mse_f1.append(np.mean(list_f1))\n",
    "    mse_gmean.append(np.mean(list_gmean))\n",
    "    mse_bacc.append(np.mean(list_bacc))\n",
    "    mse_pre.append(np.mean(list_pre))\n",
    "    mse_rec.append(np.mean(list_rec))\n",
    "    mse_spe.append(np.mean(list_spe))\n",
    "               \n",
    "res['MSE'] = [np.mean(mse_acc), np.mean(mse_f1), np.mean(mse_gmean), np.mean(mse_bacc), \n",
    "              np.mean(mse_pre), np.mean(mse_rec), np.mean(mse_spe)]\n",
    "res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d9b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AC:\", np.round(np.mean(mse_acc),4),'±',np.round(np.std(mse_acc),4))\n",
    "print(\"F1:\", np.round(np.mean(mse_f1),4),'±',np.round(np.std(mse_f1),4))\n",
    "print(\"GM:\", np.round(np.mean(mse_gmean),4),'±',np.round(np.std(mse_gmean),4))\n",
    "print(\"BA:\", np.round(np.mean(mse_bacc),4),'±',np.round(np.std(mse_bacc),4))\n",
    "print(\"PRE:\", np.round(np.mean(mse_pre),4),'±',np.round(np.std(mse_pre),4))\n",
    "print(\"REC:\", np.round(np.mean(mse_rec),4),'±',np.round(np.std(mse_rec),4))\n",
    "print(\"SPE:\", np.round(np.mean(mse_spe),4),'±',np.round(np.std(mse_spe),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ca47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each loss, do above\n",
    "# LOSS = [MSE, BCE, WBCE, Pure_Fbeta, Any_Fbeta, WBCEFL, SPLFL, \n",
    "#         Pure_Gmean, Any_Gmean, WBCEGL, SPLGL, \n",
    "#         Pure_BAccu, Any_BAccu, WBCEBL, SPLBL ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edee00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Results\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb5e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7035e163",
   "metadata": {},
   "source": [
    "## 2)CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "embedding_dim = 32\n",
    "dropout_ratio = 0.3\n",
    "num_filters = 32\n",
    "kernel_size = 5\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim))\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_acc = []\n",
    "mse_f1 = []\n",
    "mse_gmean = []\n",
    "mse_bacc = []\n",
    "mse_pre = []\n",
    "mse_rec = []\n",
    "mse_spe = []\n",
    "\n",
    "for i in range(5):\n",
    "    print('#'*50,'{0}th repeat'.format(i+1),'#'*50)\n",
    "    list_acc, list_f1, list_gmean, list_bacc, list_pre, list_rec, list_spe = make_lists()\n",
    "\n",
    "    n_iter=0\n",
    "    ###################### MLP (sigmoid // MSE) ##############################\n",
    "    for train_index, test_index in skf.split(X_padded, y):\n",
    "        n_iter += 1\n",
    "        X_train = X_padded[train_index]\n",
    "        y_train= y[train_index]\n",
    "        X_test = X_padded[test_index]\n",
    "        y_test= y[test_index]\n",
    "#         print('#'*50,'{0}th CV'.format(n_iter),'#'*50)\n",
    "    #     X_train = np.array(X_train)\n",
    "    #     y_train = np.array(y_train)\n",
    "    #     y_train = y_train.astype(float)\n",
    "    #     X_test = np.array(X_test)\n",
    "    #     y_test = np.array(y_test)\n",
    "    #     y_test = y_test.astype(float)\n",
    "\n",
    "        model = create_model()\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=0, min_delta=1e-4)\n",
    "    #     check_point = ModelCheckpoint('best_model.h5', monitor=\"val_loss\", save_best_only=True, save_weights_only=True)\n",
    "        opt = optimizers.Adam(learning_rate = 0.005)\n",
    "        model.compile(optimizer=opt, loss=MSE, metrics=['accuracy'])\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=0, epochs=epochs, batch_size = batch, )\n",
    "                            #callbacks=[early_stopping]) #, check_point])\n",
    "#         plt.plot(history.history['loss'], label='loss')\n",
    "#         plt.ylim([0, 1])\n",
    "#         plt.xlabel('Iteration',fontweight=\"bold\",fontsize = 15)\n",
    "#         plt.ylabel('Loss',fontweight=\"bold\",fontsize = 15)\n",
    "#         plt.title(\"Cost Function\",fontweight=\"bold\",fontsize = 20)\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        predicted = []\n",
    "    #     model.load_weights('best_model.h5')  # Best Model by Check_Point\n",
    "        result = model.predict(X_test)\n",
    "        for i in range(X_test.shape[0]):\n",
    "            if result[i] <= 0.5:\n",
    "                predicted.append(0)\n",
    "            else:\n",
    "                predicted.append(1)\n",
    "        get_results(y_test, predicted)\n",
    "    print(\"Acc:{}\\nF1:{}\\nGM:{}\\nBA:{}\\nPRE:{}\\nREC:{}\\nSPE:{}\\n\".format(np.mean(list_acc),np.mean(list_f1),np.mean(list_gmean),\n",
    "                                                                         np.mean(list_bacc),np.mean(list_pre),np.mean(list_rec),\n",
    "                                                                         np.mean(list_spe)))     \n",
    "    mse_acc.append(np.mean(list_acc))\n",
    "    mse_f1.append(np.mean(list_f1))\n",
    "    mse_gmean.append(np.mean(list_gmean))\n",
    "    mse_bacc.append(np.mean(list_bacc))\n",
    "    mse_pre.append(np.mean(list_pre))\n",
    "    mse_rec.append(np.mean(list_rec))\n",
    "    mse_spe.append(np.mean(list_spe))\n",
    "               \n",
    "res['MSE'] = [np.mean(mse_acc), np.mean(mse_f1), np.mean(mse_gmean), np.mean(mse_bacc), \n",
    "              np.mean(mse_pre), np.mean(mse_rec), np.mean(mse_spe)]\n",
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AC:\", np.round(np.mean(mse_acc),4),'±',np.round(np.std(mse_acc),4))\n",
    "print(\"F1:\", np.round(np.mean(mse_f1),4),'±',np.round(np.std(mse_f1),4))\n",
    "print(\"GM:\", np.round(np.mean(mse_gmean),4),'±',np.round(np.std(mse_gmean),4))\n",
    "print(\"BA:\", np.round(np.mean(mse_bacc),4),'±',np.round(np.std(mse_bacc),4))\n",
    "print(\"PRE:\", np.round(np.mean(mse_pre),4),'±',np.round(np.std(mse_pre),4))\n",
    "print(\"REC:\", np.round(np.mean(mse_rec),4),'±',np.round(np.std(mse_rec),4))\n",
    "print(\"SPE:\", np.round(np.mean(mse_spe),4),'±',np.round(np.std(mse_spe),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each loss, do above\n",
    "# LOSS = [MSE, BCE, WBCE, Pure_Fbeta, Any_Fbeta, WBCEFL, SPLFL, \n",
    "#         Pure_Gmean, Any_Gmean, WBCEGL, SPLGL, \n",
    "#         Pure_BAccu, Any_BAccu, WBCEBL, SPLBL ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8dc7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Results\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abb9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb918f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfff03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4999acc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55283213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c168a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768cc2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352261e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1b793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
